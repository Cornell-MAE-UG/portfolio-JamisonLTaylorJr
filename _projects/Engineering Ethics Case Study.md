---
layout: project
title: Engineering Ethics Case Study
description: Boeing 737 MAX & MCAS
technologies: [N/A]
image: /assets/images/ethics.png
---

**MAE 4300 – Engineering and Society**  
*Boeing 737 MAX & MCAS Case Study*

---

**Overview**

In MAE 4300, I analyzed the Boeing 737 MAX accidents as a case study in engineering ethics, focusing on how technical design decisions, organizational pressure, and regulatory structure combined to produce a major safety failure. This analysis was developed across Weeks 6–9 of the course and applies the ASME Code of Ethics to a real, safety-critical engineering system.

---

**Framing the Ethical Problem**

The initial step of this analysis focused on identifying core ethical issues raised by the MCAS system. These issues were framed as questions rather than conclusions, including:

- Should Boeing have required additional pilot training when introducing MCAS?
- Should MCAS functionality and failure modes have been disclosed more clearly to pilots and the FAA?
- Was it ethically acceptable to certify a flight-critical system with a single-sensor dependency?
- Should competitive pressure and schedule constraints have influenced safety-related design decisions?

These questions reflect ethical tensions between public safety, transparency, professional responsibility, and organizational goals.

---

**Relevant Facts and Assumptions**

From a technical perspective, MCAS relied on a single angle-of-attack sensor and could repeatedly command nose-down stabilizer trim without pilot awareness. Redundancy options were technically feasible but not implemented.

At the organizational level, Boeing operated under intense competitive pressure and within a regulatory framework that delegated significant certification authority to the manufacturer. While some details of internal decision-making remain unclear, it is reasonable to assume that cost, schedule, and market competition influenced engineering and management decisions throughout development.

Clarifying these facts and assumptions was essential for evaluating ethical responsibility without relying on hindsight bias.

---

**Ethical Analysis Using ASME Canons**

*ASME Canon 1 – Hold Paramount the Safety, Health, and Welfare of the Public*

This canon was the primary ethical principle applied. Certifying MCAS without redundancy, adequate pilot training, or clear disclosure created foreseeable safety risks. In life-critical systems such as aviation, public safety must override efficiency, cost savings, and competitive advantage.

*ASME Canon 2 – Perform Services Only in Areas of Competence*

Approving a system that pilots were not adequately trained to understand or respond to raises concerns about professional competence at the system level. Engineering responsibility includes ensuring that users of a system are prepared to interact with it safely.

*ASME Canon 3 – Issue Public Statements Truthfully and Objectively*

MCAS was not clearly communicated to pilots or the public prior to the accidents. Limited disclosure undermined informed decision-making by pilots and airlines and conflicted with the obligation to provide complete and accurate safety-related information.

*ASME Canon 4 – Act as Faithful Agents Without Conflicts of Interest*

Competitive pressure to match Airbus schedules created conflicts between Boeing’s business interests and its duty to protect public safety. Ethical engineering requires resisting pressures that compromise safety-critical decisions.

*ASME Canon 7 – Maintain Professional Integrity*

The cumulative effect of limited transparency, reduced training, and single-point failure risks reflects a broader failure of professional integrity. Ethical responsibility extends beyond meeting minimum regulatory requirements to upholding the spirit of professional standards.

Across these canons, conflicts consistently resolved in favor of **Canon 1**, reinforcing that public safety takes precedence over all other considerations.

---

**Practical Constraints on Ethical Action**
This case demonstrates how ethical failures can emerge even when individuals recognize risks. Engineers faced:
- job security concerns and hierarchical pressure  
- limited system-level visibility due to information silos  
- regulatory ambiguity caused by delegated certification authority  
- organizational culture emphasizing speed and cost control 
- lack of proper top-down view to properly evaluate possible ethical concerns

Recognizing these constraints helps explain how ethical lapses occur without attributing blame to a single individual.

---

**Prevention Strategies and Lessons Learned**

*Individual Level*
- stronger ethics and safety training focused on escalation  
- clear documentation and reporting pathways for safety concerns  

*Organizational Level*
- independent internal safety review boards  
- mandatory simulator training for new automation  
- transparent communication between engineers, pilots, and regulators  

*Systemic Level*
- reduced delegation of certification authority  
- stronger regulatory oversight of software-driven flight controls  
- industry-wide standards requiring redundancy in flight-critical systems  

Ethical engineering must be supported by systems and structures, not reliant on individual courage alone.

---

## Personal Reflection
This case reinforced that ethics is inseparable from engineering practice. Design decisions, training requirements, and communication choices all carry ethical weight. As a mechanical engineer interested in product design, this analysis has shaped how I approach my design ideation when safety, automation, and human interaction intersect.

---