---
layout: project
title: Engineering Ethics Case Study
description: Boeing 737 MAX & MCAS
technologies: [N/A]
image: /assets/images/ethics.png
---

**MAE 4300 – Engineering and Society**  
*Boeing 737 MAX & MCAS Case Study*

---

**Overview**

In MAE 4300, I analyzed the Boeing 737 MAX accidents as a case study in engineering ethics. I focused on how technical design decisions, organizational pressure, and regulatory structure came together to create a major safety failure. This work was developed across Weeks 6–9 of the course and uses the ASME Code of Ethics to evaluate a real, safety critical engineering system.

---

**Framing the Ethical Problem**

I began this analysis by identifying the main ethical issues raised by the MCAS system. Instead of jumping to conclusions, I framed them as questions.

- Should Boeing have required additional pilot training when MCAS was introduced?
- Should MCAS functionality and failure modes have been communicated more clearly to pilots and the FAA?
- Was it acceptable to certify a flight critical system that relied on a single sensor?
- Should cost, schedule, or competition have influenced safety related design decisions?

These questions highlight the tension between public safety, transparency, professional responsibility, and organizational goals.

---

**Relevant Facts and Assumptions**

From a technical standpoint, MCAS relied on a single angle of attack sensor and could repeatedly command nose down stabilizer trim without pilots fully understanding why. While redundancy was possible, it was not included in the original system design.

At the organizational level, Boeing was under strong competitive pressure and operated within a certification process that delegated significant authority to the manufacturer. While not all internal decisions are publicly known, it is reasonable to assume that cost, schedule, and market competition influenced engineering and management choices. Separating confirmed facts from assumptions helped avoid relying on hindsight when evaluating ethical responsibility.

---

**Ethical Analysis Using the ASME Canons**

***ASME Canon 1** – Hold Paramount the Safety, Health, and Welfare of the Public*

This was the most important canon in my analysis. Certifying MCAS without redundancy, adequate pilot training, or clear disclosure created foreseeable safety risks. In aviation, public safety must come before efficiency, cost savings, or competitive advantage.

***ASME Canon 2** – Perform Services Only in Areas of Competence*

Approving a system that pilots were not trained to fully understand raises concerns about competence at the system level. Engineering responsibility includes making sure users are prepared to interact with a system safely.

***ASME Canon 3** – Issue Public Statements Truthfully and Objectively*

MCAS was not clearly communicated to pilots or the public before the accidents. This limited informed decision making and conflicted with the responsibility to share complete and accurate safety information.

***ASME Canon 4** – Act as Faithful Agents Without Conflicts of Interest*

Pressure to compete with Airbus created conflicts between Boeing’s business interests and its responsibility to protect public safety. Ethical engineering requires resisting pressures that compromise safety related decisions.

***ASME Canon 7** – Maintain Professional Integrity*

When viewed together, limited transparency, reduced training, and reliance on a single sensor point to a broader breakdown in professional integrity. Ethical responsibility goes beyond meeting minimum requirements and includes upholding the intent of professional standards.

Across all of these canons, conflicts consistently resolve in favor of **Canon 1**. Public safety must always come first.

---

**Practical Constraints on Ethical Action**

This case also shows how ethical failures can happen even when risks are recognized. Engineers faced job security concerns, hierarchical pressure, limited system level visibility, and regulatory ambiguity from delegated certification authority. Organizational culture also emphasized speed and cost control. In addition, there was a lack of a clear top down view to fully evaluate ethical risk.

Recognizing these constraints helps explain how ethical lapses occur without placing blame on a single individual.

---

**Prevention Strategies and Lessons Learned**

*Individual Level*
- stronger ethics and safety training focused on escalation  
- clear documentation and reporting pathways for safety concerns  

*Organizational Level*
- independent internal safety review boards  
- mandatory simulator training for new automation  
- better communication between engineers, pilots, and regulators  

*Systemic Level*
- reduced delegation of certification authority  
- stronger oversight of software driven flight control systems  
- industry wide standards requiring redundancy in flight critical systems  

Ethical engineering needs to be supported by systems and structure. It cannot rely only on individual courage.

---

**Personal Reflection**

This case reinforced for me that ethics is not separate from engineering practice. Design decisions, training requirements, and communication choices all have real consequences. As a mechanical engineer interested in product design, this analysis has shaped how I approach design ideation when safety, automation, and human interaction intersect.

---
